{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(20000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 20 seconds\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary packages\n",
    "from neo4jrestclient.client import GraphDatabase\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import datetime\n",
    "from datetime import date\n",
    "import openpyxl\n",
    "import xlrd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "%autosave 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\manikandan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:10: DeprecationWarning: 'U' mode is deprecated\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "for csvfile in glob.glob('C:/Users/Manikandan/Desktop/Dissertation/Paper-1 Main/*.csv'):\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    with open(csvfile, 'rU') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for r, row in enumerate(reader, start=1):\n",
    "            for c, val in enumerate(row, start=1):\n",
    "                ws.cell(row=r, column=c).value = val\n",
    "    wb.save(os.path.splitext(csvfile)[0] + '.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append the data with its parent datafile name inorder to match it eid\n",
    "path = \"C:/Users/Manikandan/Desktop/Dissertation/Paper-1 Main/*.xlsx\"\n",
    "df_xl=pd.DataFrame()\n",
    "ppended_data = pd.DataFrame()\n",
    "excelname=[]\n",
    "excelyear=[]\n",
    "#loop through each file in the path\n",
    "for file in glob.glob(path):\n",
    "    wb = openpyxl.load_workbook(file)\n",
    "    \n",
    "    x=file.split('\\\\')  \n",
    "    x=x[1].split(\".\")\n",
    "    data = pd.read_excel(file)\n",
    "    data[\"Title_Cites\"]=x[0]\n",
    "    df_xl = df_xl.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the main parent paper - Parent paper 1\n",
    "main_paper=pd.read_csv(\"C:/Users/Manikandan/Desktop/Dissertation/A Big Data Provenance Model for Data Security Supervision Based on PROV-DM Model.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meger the sub paper with parent with Eid and its citations\n",
    "main_title_id=main_paper[[\"Title\",\"EID\"]]\n",
    "master=df_xl.merge(main_title_id, left_on='Title_Cites',right_on='Title', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the colums & drop unwanted columns\n",
    "master.columns = ['Authors', 'Authors_id', 'Title', 'Year', 'Source_Title','Volume','Issue','Art_no','Page_start','Page_end',\n",
    "                'Page_count','Cited_by_count','DOI','Source_EID','Source_Cites','Cites_title','Cites_EID']\n",
    "master=master.drop(columns='Cites_title',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the master data into authors and paper reference\n",
    "author_info=check[['Source_EID', 'Cites_EID', 'Authors', 'Authors_id']]\n",
    "paper_info=check[[ 'Title', 'Year', 'Source_Title','Cited_by_count','Source_EID','Source_Cites','Cites_EID','Authors', 'Authors_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\manikandan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# Spliting the end of authorid using rsplit\n",
    "s1 = author_info.iloc[:,3]\n",
    "s1=s1.str.rstrip(';')\n",
    "s1=s1.to_frame(name='Authors_id')\n",
    "author_info['Authors_id']=s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NAN and no authors available description\n",
    "author_info=author_info.dropna()\n",
    "author_info=author_info[~author_info.Authors.str.contains(\"No author name available\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text and expand i.e. stack \n",
    "a1 =author_info.Authors.str.split(',', expand=True).stack().reset_index(level=1,drop=True)\n",
    "a2 =author_info.Authors_id.str.split(';', expand=True).stack().reset_index(level=1,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the expanded columns\n",
    "df1=pd.concat([a1,a2],axis=1 ,keys=['Authors','Authors_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the new column with original data\n",
    "author_info_clean=author_info.drop(['Authors','Authors_id'], axis=1).join(df1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\manikandan\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "s1 =paper_info.iloc[:,8]\n",
    "s1=s1.str.rstrip(';')\n",
    "s1=s1.to_frame(name='Authors_id')\n",
    "paper_info['Authors_id']=s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping NAN and no authors available description\n",
    "paper_info=paper_info.dropna()\n",
    "paper_info=paper_info[~paper_info.Authors.str.contains(\"No author name available\")]\n",
    "paper_info=paper_info[~paper_info.Title.str.contains(\"No title available\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the text and expand i.e. stack \n",
    "a1 =paper_info.Authors.str.split(',', expand=True).stack().reset_index(level=1,drop=True)\n",
    "a2 =paper_info.Authors_id.str.split(';', expand=True).stack().reset_index(level=1,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat the expanded columns\n",
    "df2=pd.concat([a1,a2],axis=1 ,keys=['Authors','Authors_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the new column with original data\n",
    "paper_info_clean=paper_info.drop(['Authors','Authors_id'], axis=1).join(df2).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing reusable functions\n",
    "\n",
    "#Function 1 : # Convert csv into excel\n",
    "\n",
    "def convert_csv_to_excel(path):\n",
    "       for csvfile in glob.glob(path+'*.csv'):\n",
    "            wb = openpyxl.Workbook()\n",
    "            ws = wb.active\n",
    "            with open(csvfile, 'rU') as f:\n",
    "                reader = csv.reader(f)\n",
    "                for r, row in enumerate(reader, start=1):\n",
    "                    for c, val in enumerate(row, start=1):\n",
    "                        ws.cell(row=r, column=c).value = val\n",
    "            wb.save(os.path.splitext(csvfile)[0] + '.xlsx')\n",
    "\n",
    "#Function 2 : # append the data with its parent datafile name inorder to match it eid\n",
    "\n",
    "def append_data_master(path):\n",
    "    \n",
    "    path = path+'*.xlsx'\n",
    "    df_xl=pd.DataFrame()\n",
    "    ppended_data = pd.DataFrame()\n",
    "    excelname=[]\n",
    "    excelyear=[]\n",
    "    #loop through each file in the path\n",
    "    for file in glob.glob(path):\n",
    "        wb = openpyxl.load_workbook(file)\n",
    "\n",
    "        x=file.split('\\\\')  \n",
    "        x=x[1].split(\".\")\n",
    "        data = pd.read_excel(file)\n",
    "        data[\"Title_Cites\"]=x[0]\n",
    "        df_xl = df_xl.append(data)\n",
    "        \n",
    "        \n",
    "#Function 3: # Merging the sub papers with master paper\n",
    "\n",
    "def merge_sub_master(path):\n",
    "        \n",
    "        # Reading the main parent paper - Parent paper 1\n",
    "        main_paper=pd.read_csv(path)\n",
    "        \n",
    "        # Meger the sub paper with parent with Eid and its citations\n",
    "        main_title_id=main_paper[[\"Title\",\"EID\"]]\n",
    "        master=df_xl.merge(main_title_id, left_on='Title_Cites',right_on='Title', how='left')\n",
    "       \n",
    "        # Rename the colums & drop unwanted columns\n",
    "        master.columns = ['Authors', 'Authors_id', 'Title', 'Year', 'Source_Title','Volume','Issue','Art_no','Page_start','Page_end',\n",
    "                'Page_count','Cited_by_count','DOI','Source_EID','Source_Cites','Cites_title','Cites_EID']\n",
    "        master=master.drop(columns='Cites_title',axis=1)\n",
    "        \n",
    "        # Split the master data into authors and paper reference\n",
    "        author_info=check[['Source_EID', 'Cites_EID', 'Authors', 'Authors_id']]\n",
    "        paper_info=check[[ 'Title', 'Year', 'Source_Title','Cited_by_count','Source_EID','Source_Cites','Cites_EID','Authors', 'Authors_id']]\n",
    "        \n",
    "        \n",
    "#Function 4: #Expanding the author info in authors data\n",
    "\n",
    "def expand_author():\n",
    "    \n",
    "    # Spliting the end of authorid using rsplit\n",
    "    s1 = author_info.iloc[:,3]\n",
    "    s1=s1.str.rstrip(';')\n",
    "    s1=s1.to_frame(name='Authors_id')\n",
    "    author_info['Authors_id']=s1\n",
    "    \n",
    "    # Dropping NAN and no authors available description\n",
    "    author_info=author_info.dropna()\n",
    "    author_info=author_info[~author_info.Authors.str.contains(\"No author name available\")]\n",
    "    \n",
    "    # Split the text and expand i.e. stack \n",
    "    a1 =author_info.Authors.str.split(',', expand=True).stack().reset_index(level=1,drop=True)\n",
    "    a2 =author_info.Authors_id.str.split(';', expand=True).stack().reset_index(level=1,drop=True)\n",
    "    \n",
    "    # Concat the expanded columns\n",
    "    df1=pd.concat([a1,a2],axis=1 ,keys=['Authors','Authors_id'])\n",
    "    \n",
    "    # Join the new column with original data\n",
    "    author_info_clean=author_info.drop(['Authors','Authors_id'], axis=1).join(df1).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "#Function 5: #Expanding the author info in papers data\n",
    "\n",
    "def expand_author_paper():\n",
    "    \n",
    "    # Spliting the end of authorid using rsplit\n",
    "    s1 =paper_info.iloc[:,8]\n",
    "    s1=s1.str.rstrip(';')\n",
    "    s1=s1.to_frame(name='Authors_id')\n",
    "    paper_info['Authors_id']=s1\n",
    "\n",
    "    # Dropping NAN and no authors available description\n",
    "    paper_info=paper_info.dropna()\n",
    "    paper_info=paper_info[~paper_info.Authors.str.contains(\"No author name available\")]\n",
    "    paper_info=paper_info[~paper_info.Title.str.contains(\"No title available\")]\n",
    "    \n",
    "    # Split the text and expand i.e. stack \n",
    "    a1 =paper_info.Authors.str.split(',', expand=True).stack().reset_index(level=1,drop=True)\n",
    "    a2 =paper_info.Authors_id.str.split(';', expand=True).stack().reset_index(level=1,drop=True)\n",
    "    \n",
    "    # Concat the expanded columns\n",
    "    df2=pd.concat([a1,a2],axis=1 ,keys=['Authors','Authors_id'])\n",
    "    \n",
    "    # Join the new column with original data\n",
    "    paper_info_clean=paper_info.drop(['Authors','Authors_id'], axis=1).join(df2).reset_index(drop=True)\n",
    "    \n",
    "#Function 6: #Concatenate authors and paper info into a seperate master files\n",
    "\n",
    "def concatenate_master_authors():\n",
    "    master_author_info=pd.concat([master_author_info, author_info_clean])\n",
    "    master_paper_info=pd.concat([master_paper_info, paper_info_clean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
